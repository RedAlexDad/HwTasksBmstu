


import timeit
import time
import sys
import os
import re
import numpy as np
import pandas as pd
import seaborn as sb
from IPython.display import display, HTML
from datetime import datetime

import matplotlib.pyplot as plt

from scipy import stats as st
# Тренды и сезонность
from statsmodels.tsa.seasonal import seasonal_decompose
# Проверка на стационарность
from statsmodels.tsa.stattools import adfuller, kpss
# Проверка на дисперсию с помощью теста Андерсона-Дарлинга
from scipy.stats import anderson

# Разбиение на обучающую, валидационную и тестовую выборку
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, TimeSeriesSplit

# Масштабируемость модели
from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder

# Многозадачная регрессия
from sklearn.multioutput import MultiOutputRegressor
# Для машинного обучения
from lightgbm import LGBMRegressor
from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from catboost import CatBoostRegressor
# Метод ближайшего соседа KNN
from sklearn.neighbors import KNeighborsRegressor
# Метод опорного вектора, SVR - для регрессии
from sklearn.svm import SVR

# Метрики
from sklearn.metrics import mean_squared_error

from sklearn.pipeline import make_pipeline

# Нейросети
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, TensorDataset
import torch.optim as optim
# Для сборщика мусора
import gc

# NODE
from torchdiffeq import odeint


# Тестирование модели
t_test = torch.linspace(0, 1, 200)
y_test = target_function(t_test)
model = odeint(ode_func, target_function(torch.tensor([0.])).unsqueeze(0), t_test) # Вычисляем model для тестовых данных
predictions = model.squeeze()


# Вычисление RMSE на тестовом наборе данных
test_rmse = rmse(predictions, y_test)
print(f"RMSE on test set: {test_rmse.item():.4f}")


# Визуализация результатов
plt.plot(t_test, y_test.squeeze().detach().numpy(), label='Истинная функция')
plt.plot(t_test, predictions.squeeze().detach().numpy(), label='Прогноз Neural ODE')
plt.legend()
plt.show()




















df = pd.read_csv('Amp_C_train.txt')





df.info()


# Приведение к нижнему регистру названия колонки
df.columns = df.columns.str.lower()


df.head()








# Установка колонки 'time' в качестве индекса
df.set_index('time', inplace=True)





df['input'] = df['input'].apply(lambda x: complex(x.strip('()').replace('i', 'j')))
df['output'] = df['output'].apply(lambda x: complex(x.strip('()').replace('i', 'j')))





df['input_real'] = df['input'].apply(np.real)
df['input_imag'] = df['input'].apply(np.imag)
df['output_real'] = df['output'].apply(np.real)
df['output_imag'] = df['output'].apply(np.imag)


df.head()


df.info()


df = df.drop(['input', 'output'], axis=1)


df.describe()





def draw_plot_signal(signal_type, time_start=0, time_end=1e-6):
    # Фильтрация данных по временной отметке
    filtered_data = df[(df.index >= time_start) & (df.index <= time_end)]
    time = filtered_data.index

    # Построение объединенного графика
    plt.figure(figsize=(10, 6))
    
    # Входной сигнал
    plt.plot(time, filtered_data[f'{signal_type}_real'], label=f'{signal_type} Real Part', color='blue', linestyle='-')
    plt.plot(time, filtered_data[f'{signal_type}_imag'], label=f'{signal_type} Imaginary Part', color='red', linestyle='-')
    
    plt.title('Input and Output Signals')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.legend()
    plt.grid(True)
    plt.show()


def draw_all_plot_signal(time_start=0, time_end=1e-6):
    # Фильтрация данных по временной отметке
    filtered_data = df[(df.index >= time_start) & (df.index <= time_end)]
    time = filtered_data.index
    
    plt.figure(figsize=(15, 10))

    # График реальной части входного сигнала
    plt.subplot(2, 2, 1)
    plt.plot(time, filtered_data['input_real'], label='Real Part')
    plt.title('Real Part of input Signal')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.grid(True)
    
    # График мнимой части входного сигнала
    plt.subplot(2, 2, 2)
    plt.plot(time, filtered_data['input_imag'], label='Imaginary Part', color='orange')
    plt.title('Imaginary Part of input Signal')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.grid(True)
    
    # График реальной части выходного сигнала
    plt.subplot(2, 2, 3)
    plt.plot(time, filtered_data['output_real'], label='Real Part')
    plt.title('Real Part of output Signal')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.grid(True)
    
    # График мнимой части выходного сигнала
    plt.subplot(2, 2, 4)
    plt.plot(time, filtered_data['output_imag'], label='Imaginary Part', color='orange')
    plt.title('Imaginary Part of output Signal')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.grid(True)
    
    plt.tight_layout()
    plt.show()


draw_plot_signal('input', time_start=1e-8, time_end=0.3e-6)


draw_plot_signal('output', time_start=1e-8, time_end=0.3e-6)


draw_all_plot_signal(time_start=1e-7, time_end=0.3e-6)





# Здесь будем сохранить результаты обучения
results = pd.DataFrame()

# А это будет счетчтиком для нумерация моеделй
count_model = 0


df.info()


# Проверка наличия CUDA
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

if device.type == 'cuda':
    print("CUDA is available!")
    print(f"Device name: {torch.cuda.get_device_name(0)}")
    print(f"CUDA capability: {torch.cuda.get_device_capability(0)}")
    print(f"Driver version: {torch.version.cuda}")
    print(f"Device count: {torch.cuda.device_count()}")
    print(f"Current device: {torch.cuda.current_device()}")
else:
    print("CUDA is not available. Running on CPU.")





class ODEFunc(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(ODEFunc, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),  # Добавлен слой
            nn.Tanh(),                           # Добавлен слой
            nn.Linear(hidden_dim, input_dim)
        )

    def forward(self, t, x):
        return self.net(x)


# Параметры
input_dim = 1
hidden_dim = 16
t_span = torch.linspace(0, 1, 100)
x0 = torch.tensor([1.0])


# Создание модели NODE
func = ODEFunc(input_dim, hidden_dim)
# Решение дифференциального уравнения
solution = odeint(func, x0, t_span)


# Вывод результата
print(solution.shape) # torch.Size([100, 1]) - 100 точек во времени, 1 значение в каждой точке


# Создаем случайную кривую для обучения
def create_target_function(t):
    return torch.sin(t * 2 * np.pi) + 0.5 * torch.sin(t * 5 * np.pi)


# Параметры
input_dim = 1
hidden_dim = 32
t_span_train = torch.linspace(0, 1, 100).to(device)
t_span_test = torch.linspace(0, 1.2, 120).to(device)
x0 = torch.tensor([0.0]).to(device)


# Создаем целевую функцию
target_y_train = create_target_function(t_span_train).to(device)
target_y_test = create_target_function(t_span_test).to(device)


# Модель NODE
func = ODEFunc(input_dim, hidden_dim).to(device)
optimizer = torch.optim.Adam(func.parameters(), lr=0.01)


%%time
epochs = 100
for epoch in range(epochs):
    optimizer.zero_grad()
    solution = odeint(func, x0, t_span_train)
    
    # RMSE Loss с использованием PyTorch
    loss = torch.sqrt(torch.mean((solution.squeeze() - target_y_train)**2)) 
    
    loss.backward()
    optimizer.step()
    # if (epoch+1) % 100 == 0:
    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')


with torch.no_grad():
    solution_test = odeint(func, x0, t_span_test)


# Перенос на CPU для визуализации
t_span_train = t_span_train.cpu()
t_span_test = t_span_test.cpu()
target_y_train = target_y_train.cpu()
target_y_test = target_y_test.cpu()
solution = solution.cpu()
solution_test = solution_test.cpu()


plt.plot(t_span_train, target_y_train.numpy(), label='Целевая функция (обучение)')
plt.plot(t_span_test, target_y_test.numpy(), label='Целевая функция (тестирование)')
plt.plot(t_span_train, solution.detach().numpy(), label='Предсказание (обучение)')
plt.plot(t_span_test, solution_test.detach().numpy(), label='Предсказание (тестирование)')
plt.legend()
plt.show()

















# Параметры задержки p
p=30 # Входная задержка
q=5  # Выходная задержка

# Создадим объект CTRNN
ctdrnn = CTDRNN(
    input_size=2 * (p + 1 + q), 
    hidden_sizes=[128, 256, 256, 128, 64],
    output_size=2, 
    num_layers=2,
    num_epochs=3,
    learning_rate=0.001,
    p=p,
    q=q,
    # batch_size=256
    # batch_size=1024
    batch_size=2048
)


# Вывод параметров в виде HTML-таблицы
ctdrnn.print_params()


%%time
# Подготовка данных
X_seq, Y_seq = ctdrnn.prepare_data(df)


# Вывод размеров X_seq и Y_seq
print(f"Shape of X_seq (N, {ctdrnn.input_size}):", X_seq.shape) 
print(f"Shape of Y_seq (N, {ctdrnn.output_size}):", Y_seq.shape)

# Описание входных данных:
print("\nВходные данные X_seq:")
print(f" - {p + 1} значений 'input_real' из прошлого")
print(f" - {p + 1} значений 'input_imag' из прошлого")
print(f" - {q} значений 'output_real' из прошлого")
print(f" - {q} значений 'output_imag' из прошлого")

# Описание выходных данных:
print("\nВыходные данные Y_seq:")
print(f" - Предсказанное значение 'output_real'")
print(f" - Предсказанное значение 'output_imag'")





%%time
# Обучим модель
ctdrnn.train()


# График обучения
ctdrnn.plot_loss()





%%time
# Сделаем предсказания
# X_seq - входные данные для предсказания
Y_pred = ctdrnn.predict(X_seq)


# Создаем DataFrame из предсказаний
df_predictions = pd.DataFrame(Y_pred, columns=['pred_real', 'pred_imag'])

# Добавляем столбец с индексом (если необходимо)
df_predictions['index'] = np.arange(len(Y_pred))

# Сохраняем в CSV
df_predictions.to_csv('predictions.csv', index=False)


# Оценка модель
# Y_seq - реальные выходные данные
rmse_real, rmse_imag = ctdrnn.evaluate(Y_seq, Y_pred)

print(f'RMSE (Real part): {rmse_real}')
print(f'RMSE (Imaginary part): {rmse_imag}')


# Сохранение результатов
results[count_model] = ctdrnn.save_results(Y_seq, Y_pred, rmse_real, rmse_imag)

# display(results)
count_model += 1





# Сохраним модель
ctdrnn.save_model('ctdrnn') 


# Построим графики
info_result = pd.DataFrame({
    'default_real': Y_seq[:, 0],  # Реальные значения (вещественная часть)
    'default_imag': Y_seq[:, 1],  # Реальные значения (мнимая часть)
    'pred_real': Y_pred[:, 0],    # Предсказанные значения (вещественная часть)
    'pred_imag': Y_pred[:, 1]     # Предсказанные значения (мнимая часть)
})


info_result.index = range(len(Y_seq))  # Пример временной шкалы: индексы от 0 до количества наблюдений
ctdrnn.plot_predictions_vs_real(info_result, time_start=0, time_end=1.005e2)


ctdrnn.plot_predictions_vs_real(info_result, time_start=1e4, time_end=1.005e4)





results = pd.DataFrame(results).T


# Смотрим на результаты
display(results)


# Рассчитываем рейтинг с учетом указанных приоритетов
results['RATING'] = (
    0.45 * (1 - (results['RMSE VALID REAL'] / results['RMSE VALID REAL'].max())) +
    0.45 * (1 - (results['RMSE VALID IMAG'] / results['RMSE VALID IMAG'].max())) +
    0.1 * (1 - (results['TIME TRAINING [s]'] / results['TIME TRAINING [s]'].max()))
)

# Сортируем DataFrame по убыванию рейтинга
results = results.sort_values(by='RATING', ascending=False)


# Смотрим на результаты
display(results)



